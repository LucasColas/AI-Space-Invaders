{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Space Invaders OpenAI Gym in Colaboratory.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsSGgH2Y0apl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#          _____                _____                    _____                    _____                    _____                    _____          \n",
        "#         /\\    \\              /\\    \\                  /\\    \\                  /\\    \\                  /\\    \\                  /\\    \\         \n",
        "#        /::\\    \\            /::\\    \\                /::\\    \\                /::\\    \\                /::\\    \\                /::\\    \\        \n",
        "#       /::::\\    \\           \\:::\\    \\              /::::\\    \\              /::::\\    \\              /::::\\    \\               \\:::\\    \\       \n",
        "#      /::::::\\    \\           \\:::\\    \\            /::::::\\    \\            /::::::\\    \\            /::::::\\    \\               \\:::\\    \\      \n",
        "#     /:::/\\:::\\    \\           \\:::\\    \\          /:::/\\:::\\    \\          /:::/\\:::\\    \\          /:::/\\:::\\    \\               \\:::\\    \\     \n",
        "#    /:::/__\\:::\\    \\           \\:::\\    \\        /:::/__\\:::\\    \\        /:::/__\\:::\\    \\        /:::/__\\:::\\    \\               \\:::\\    \\    \n",
        "#    \\:::\\   \\:::\\    \\          /::::\\    \\      /::::\\   \\:::\\    \\      /::::\\   \\:::\\    \\      /::::\\   \\:::\\    \\              /::::\\    \\   \n",
        "#  ___\\:::\\   \\:::\\    \\        /::::::\\    \\    /::::::\\   \\:::\\    \\    /::::::\\   \\:::\\    \\    /::::::\\   \\:::\\    \\    ____    /::::::\\    \\  \n",
        "# /\\   \\:::\\   \\:::\\    \\      /:::/\\:::\\    \\  /:::/\\:::\\   \\:::\\    \\  /:::/\\:::\\   \\:::\\____\\  /:::/\\:::\\   \\:::\\    \\  /\\   \\  /:::/\\:::\\    \\ \n",
        "#/::\\   \\:::\\   \\:::\\____\\    /:::/  \\:::\\____\\/:::/  \\:::\\   \\:::\\____\\/:::/  \\:::\\   \\:::|    |/:::/  \\:::\\   \\:::\\____\\/::\\   \\/:::/  \\:::\\____\\\n",
        "#\\:::\\   \\:::\\   \\::/    /   /:::/    \\::/    /\\::/    \\:::\\  /:::/    /\\::/   |::::\\  /:::|____|\\::/    \\:::\\  /:::/    /\\:::\\  /:::/    \\::/    /\n",
        "# \\:::\\   \\:::\\   \\/____/   /:::/    / \\/____/  \\/____/ \\:::\\/:::/    /  \\/____|:::::\\/:::/    /  \\/____/ \\:::\\/:::/    /  \\:::\\/:::/    / \\/____/ \n",
        "#  \\:::\\   \\:::\\    \\      /:::/    /                    \\::::::/    /         |:::::::::/    /            \\::::::/    /    \\::::::/    /          \n",
        "#   \\:::\\   \\:::\\____\\    /:::/    /                      \\::::/    /          |::|\\::::/    /              \\::::/    /      \\::::/____/           \n",
        "#    \\:::\\  /:::/    /    \\::/    /                       /:::/    /           |::| \\::/____/               /:::/    /        \\:::\\    \\           \n",
        "#     \\:::\\/:::/    /      \\/____/                       /:::/    /            |::|  ~|                    /:::/    /          \\:::\\    \\          \n",
        "#      \\::::::/    /                                    /:::/    /             |::|   |                   /:::/    /            \\:::\\    \\         \n",
        "#       \\::::/    /                                    /:::/    /              \\::|   |                  /:::/    /              \\:::\\____\\        \n",
        "#        \\::/    /                                     \\::/    /                \\:|   |                  \\::/    /                \\::/    /        \n",
        "#         \\/____/                                       \\/____/                  \\|___|                   \\/____/                  \\/____/    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odNaDE1zyrL2",
        "colab_type": "text"
      },
      "source": [
        "# install dependancies, takes around 45 seconds\n",
        "\n",
        "Rendering Dependancies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-AxnvAVyzQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8A-1LTSH88EE",
        "colab_type": "text"
      },
      "source": [
        "Pacman Dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCelFzWY9MBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get update > /dev/null 2>&1\n",
        "!apt-get install cmake > /dev/null 2>&1\n",
        "!pip install --upgrade setuptools 2>&1\n",
        "!pip install ez_setup > /dev/null 2>&1\n",
        "!pip install gym[atari] > /dev/null 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf3DAgmjCIVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "\n",
        "# install required system dependencies\n",
        "apt-get install -y xvfb x11-utils\n",
        "\n",
        "# install required python dependencies (might need to install additional gym extras depending)\n",
        "pip install gym[box2d]==0.17.* pyvirtualdisplay==0.2.* PyOpenGL==3.1.* PyOpenGL-accelerate==3.1.*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APXSx7hg19TH",
        "colab_type": "text"
      },
      "source": [
        "# Imports and Helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdb2JwZy4jGj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import random\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from skimage import transform\n",
        "from skimage.color import rgb2gray\n",
        "from collections import deque\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQEtc28G4niA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9UWeToN4r7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3BGbWOu179M",
        "colab_type": "text"
      },
      "source": [
        "# Space Invaders !\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGEFMfDOzLen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = wrap_env(gym.make(\"SpaceInvaders-v0\")) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BmIlXhe9Q89",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"action space : \", env.action_space)\n",
        "print(\"frame size : \",env.observation_space)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nj5sjsk15IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "observation = env.reset()\n",
        "\n",
        "while True:\n",
        "  \n",
        "    env.render()\n",
        "    \n",
        "    #your agent goes here\n",
        "    action = env.action_space.sample() \n",
        "         \n",
        "    observation, reward, done, info = env.step(action) \n",
        "   \n",
        "        \n",
        "    if done: \n",
        "      break;\n",
        "            \n",
        "env.close()\n",
        "show_video()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3RtqYntSM0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pre_processing(frame):\n",
        "\n",
        "  frame_grey = rgb2gray(frame)\n",
        "\n",
        "  crop_frame = frame_grey[8:-12, 4:-12]\n",
        "\n",
        "  normalize_frame = crop_frame/255.0\n",
        "\n",
        "  preprocessed_frame = transform.resize(normalize_frame, [110,84])\n",
        "\n",
        "  return preprocessed_frame"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-me0-DsmSM_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_size = 4\n",
        "\n",
        "stacked_frames = deque([np.zeros((110, 84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "\n",
        "def stack_frame(stacked_frames, state, is_new_episode):\n",
        "  frame = pre_processing(state)\n",
        "\n",
        "  if is_new_episode:\n",
        "\n",
        "    stacked_frames = deque([np.zeros((110, 84), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "\n",
        "    stacked_frames.append(frame)\n",
        "    stacked_frames.append(frame)\n",
        "    stacked_frames.append(frame)\n",
        "    stacked_frames.append(frame)\n",
        "\n",
        "    stacked_state = np.stack(stacked_frames, axis=2)\n",
        "\n",
        "  else:\n",
        "    stacked_frames.append(frame)\n",
        "\n",
        "    stacked_state = np.stack(stack_frames, axis=2)\n",
        "\n",
        "  \n",
        "  return stacked_state, stacked_frames\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gha-B0nSNCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# HYPERPARAMETERS\n",
        "\n",
        "state_size = [110,84,4]\n",
        "action_size = env.action_space.n\n",
        "\n",
        "Alpha = 0.0003\n",
        "Gamma = 0.9\n",
        "\n",
        "total_episodes = 100\n",
        "max_steps = 60000\n",
        "batch_size = 64\n",
        "\n",
        "Epsilon_starte = 1.0\n",
        "Epsilon_decay = 0.01\n",
        "Epsilon_min = 0.001\n",
        "\n",
        "pretrain_length = batch_size \n",
        "memory_size = 1000000\n",
        "\n",
        "stack_size = 4\n",
        "\n",
        "training = False\n",
        "rendering = True \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iV5CMJ9tSNIf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQNetwork:\n",
        "    def __init__(self, state_size, action_size, learning_rate, name='DQNetwork'):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        tf.compat.v1.disable_eager_execution()\n",
        "        \n",
        "        with tf.compat.v1.variable_scope(name):\n",
        "            # We create the placeholders\n",
        "            # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
        "            # [None, 84, 84, 4]\n",
        "            self.inputs_ = tf.compat.v1.placeholder(tf.float32, [None, *state_size], name=\"inputs\")\n",
        "            self.actions_ = tf.compat.v1.placeholder(tf.float32, [None, self.action_size], name=\"actions_\")\n",
        "            \n",
        "            # Remember that target_Q is the R(s,a) + ymax Qhat(s', a')\n",
        "            self.target_Q = tf.compat.v1.placeholder(tf.float32, [None], name=\"target\")\n",
        "            \n",
        "            \"\"\"\n",
        "            First convnet:\n",
        "            CNN\n",
        "            ELU\n",
        "            \"\"\"\n",
        "            # Input is 110x84x4\n",
        "            self.conv1 = tf.compat.v1.layers.conv2d(inputs = self.inputs_,\n",
        "                                         filters = 32,\n",
        "                                         kernel_size = [8,8],\n",
        "                                         strides = [4,4],\n",
        "                                         padding = \"VALID\",\n",
        "                                          kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
        "                                         name = \"conv1\")\n",
        "            \n",
        "            self.conv1_out = tf.nn.elu(self.conv1, name=\"conv1_out\")\n",
        "            \n",
        "            \"\"\"\n",
        "            Second convnet:\n",
        "            CNN\n",
        "            ELU\n",
        "            \"\"\"\n",
        "            self.conv2 = tf.compat.v1.layers.conv2d(inputs = self.conv1_out,\n",
        "                                 filters = 64,\n",
        "                                 kernel_size = [4,4],\n",
        "                                 strides = [2,2],\n",
        "                                 padding = \"VALID\",\n",
        "                                kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
        "                                 name = \"conv2\")\n",
        "\n",
        "            self.conv2_out = tf.nn.elu(self.conv2, name=\"conv2_out\")            \n",
        "            \n",
        "            \"\"\"\n",
        "            Third convnet:\n",
        "            CNN\n",
        "            ELU\n",
        "            \"\"\"\n",
        "            self.conv3 = tf.compat.v1.layers.conv2d(inputs = self.conv2_out,\n",
        "                                 filters = 64,\n",
        "                                 kernel_size = [3,3],\n",
        "                                 strides = [2,2],\n",
        "                                 padding = \"VALID\",\n",
        "                                kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
        "                                 name = \"conv3\")\n",
        "\n",
        "            self.conv3_out = tf.nn.elu(self.conv3, name=\"conv3_out\")\n",
        "            \n",
        "            self.flatten = tf.compat.v1.layers.flatten(self.conv3_out)\n",
        "            \n",
        "            self.fc = tf.compat.v1.layers.dense(inputs = self.flatten,\n",
        "                                  units = 512,\n",
        "                                  activation = tf.nn.elu,\n",
        "                                       kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
        "                                name=\"fc1\")\n",
        "            \n",
        "            self.output = tf.compat.v1.layers.dense(inputs = self.fc, \n",
        "                                           kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
        "                                          units = self.action_size, \n",
        "                                        activation=None)\n",
        "            \n",
        "\n",
        "  \n",
        "            # Q is our predicted Q value.\n",
        "            self.Q = tf.reduce_sum(tf.multiply(self.output, self.actions_))\n",
        "            \n",
        "            # The loss is the difference between our predicted Q_values and the Q_target\n",
        "            # Sum(Qtarget - Q)^2\n",
        "            self.loss = tf.reduce_mean(tf.square(self.target_Q - self.Q))\n",
        "            \n",
        "            self.optimizer = tf.optimizers.Adam(self.learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SmkErIzSNPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "DQNetwork = DQNetwork(state_size, action_size, Alpha)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUW3BsGESNUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i44Q3RCBSNMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TbT70nCSNHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}